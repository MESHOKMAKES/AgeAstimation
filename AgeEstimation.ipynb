{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XgZl8JiHUdY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/SanyeungWang/PML.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LtLY544HiaE",
        "outputId": "4e65a7f8-ac79-402d-b3b7-280226abb02d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/PML\n"
          ]
        }
      ],
      "source": [
        "%cd PML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw4EDaFzLRHB",
        "outputId": "f048f661-22b7-4765-dc1e-58cc93373d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAs-n4K0JKB4",
        "outputId": "4ce5708e-8ea7-4277-c16a-42fba8f322f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHb-AkUR-5t4",
        "outputId": "7ed54630-4232-432a-a6ad-1f12a36b1057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting facenet_pytorch\n",
            "  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 14.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (2.23.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from facenet_pytorch) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->facenet_pytorch) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet_pytorch) (4.1.1)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.8/dist-packages (from torchvision->facenet_pytorch) (1.12.1+cu113)\n",
            "Installing collected packages: facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install facenet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxCWsHBsEaA3",
        "outputId": "f94697ad-5868-416f-f56f-1bac8e77e9d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytelegrambotapi\n",
            "  Downloading pyTelegramBotAPI-4.8.0.tar.gz (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytelegrambotapi) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (1.24.3)\n",
            "Building wheels for collected packages: pytelegrambotapi\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-4.8.0-py3-none-any.whl size=200125 sha256=60ad89497b7211b167e7ac76590819c16ee7276578bf8004665f815312e94f06\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/05/70/8409792e663e67a70e057df1f18d070105c1c457b3f410bbb0\n",
            "Successfully built pytelegrambotapi\n",
            "Installing collected packages: pytelegrambotapi\n",
            "Successfully installed pytelegrambotapi-4.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytelegrambotapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cW6oeYveH3O-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "# from model.resnet import resnet34\n",
        "from scipy.spatial.distance import euclidean\n",
        "from facenet_pytorch import MTCNN\n",
        "import math\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import functools\n",
        "import telebot\n",
        "from telebot.types import InputMediaPhoto\n",
        "import shutil\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IKwUsmlSBfr"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "def cosine_distance(x, y):\n",
        "    if x.ndim == 1:\n",
        "        x_norm = np.linalg.norm(x)\n",
        "        y_norm = np.linalg.norm(y)\n",
        "    elif x.ndim == 2:\n",
        "        x_norm = np.linalg.norm(x, axis=1, keepdims=True)\n",
        "        y_norm = np.linalg.norm(y, axis=1, keepdims=True)\n",
        "\n",
        "    np.seterr(divide='ignore', invalid='ignore')\n",
        "    s = np.dot(x, y.T)/(x_norm*y_norm)\n",
        "    s *= -1\n",
        "    dist = s + 1\n",
        "    dist = np.clip(dist, 0, 2)\n",
        "    if x is y or y is None:\n",
        "        dist[np.diag_indices_from(dist)] = 0.0\n",
        "    if np.any(np.isnan(dist)):\n",
        "        if x.ndim == 1:\n",
        "            dist = 1.\n",
        "        else:\n",
        "            dist[np.isnan(dist)] = 1.\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BqoCgTDSdX2"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1C1P_ogSiVN"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mjd43uFRo1M"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "\n",
        "        # define margin cnn\n",
        "        self.conv1_d = nn.Conv1d(101, 64, kernel_size=7, stride=2, padding=3, bias=False)  # 614/2 64\n",
        "        self.bn1_d = nn.BatchNorm1d(64)\n",
        "        # 150 64\n",
        "        self.layer1_d = nn.Sequential(\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.Conv1d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # output 75 128\n",
        "        self.layer2_d = nn.Sequential(\n",
        "            nn.Conv1d(64, 128, kernel_size=3, stride=2, padding=1),  # conv replacing pooling\n",
        "            nn.Conv1d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # output 37 256\n",
        "        self.layer3_d = nn.Sequential(\n",
        "            nn.Conv1d(128, 256, kernel_size=3, stride=2, padding=1),  # conv replacing pooling\n",
        "            nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        # output 20 512\n",
        "        self.layer4_d = nn.Sequential(\n",
        "            nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1),  # conv replacing pooling\n",
        "            nn.Conv1d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.avgpool_d = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc_d = nn.Linear(512, 101)  # the number of margin_l=101\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.Conv1d)):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm, nn.BatchNorm1d)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def margin_long_tail(self, x):\n",
        "        x = self.conv1_d(x)\n",
        "        x = self.bn1_d(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1_d(x)\n",
        "        x = self.layer2_d(x)\n",
        "        x = self.layer3_d(x)\n",
        "        x = self.layer4_d(x)\n",
        "        x = self.avgpool_d(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_d(x)\n",
        "        return x\n",
        "\n",
        "    def margin_miu(self, x):\n",
        "        x = self.conv1_d(x)\n",
        "        x = self.bn1_d(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1_d(x)\n",
        "        x = self.layer2_d(x)\n",
        "        x = self.layer3_d(x)\n",
        "        x = self.layer4_d(x)\n",
        "        x = self.avgpool_d(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_d(x)\n",
        "        x = (x-torch.min(x))/(torch.max(x)-torch.min(x))*101\n",
        "        return x\n",
        "\n",
        "    def margin_sigma(self, x):\n",
        "        x = self.conv1_d(x)\n",
        "        x = self.bn1_d(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer1_d(x)\n",
        "        x = self.layer2_d(x)\n",
        "        x = self.layer3_d(x)\n",
        "        x = self.layer4_d(x)\n",
        "        x = self.avgpool_d(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_d(x)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def gaussian(z, age, m_p_miu, m_p_sigma):  # Calculate the Gaussian distribution for each age\n",
        "        x = torch.linspace(0, 100, 101).expand([z.shape[0], -1]).cuda()\n",
        "        pi = torch.Tensor([3.1415926]).cuda()\n",
        "        u = m_p_miu.T[age]\n",
        "        sig = m_p_sigma.T[age]\n",
        "        m_p = torch.exp(-torch.pow((x - u), 2)/(2 * torch.pow(sig, 2))) / (torch.sqrt(2 * pi) * sig)\n",
        "        return m_p\n",
        "\n",
        "    @staticmethod\n",
        "    def distributed_softmax(x, margin):\n",
        "        a = torch.ones(x.shape[1]).cuda()\n",
        "        mask = torch.diag(a).cuda()  # 1D vector  Output a 2D square matrix with input as diagonal elements\n",
        "        mask = (1 - mask).expand((x.shape[0], -1, -1))  # diagonal is 0, the others are 1\n",
        "\n",
        "        b = x.expand([x.shape[1], -1, -1]).permute(1, 0, 2)  # batch_size, multi, score\n",
        "        b = b * mask\n",
        "        b = torch.sum(torch.exp(b), dim=2) - 1  # eliminate exp(0) sum of the negative score\n",
        "        y = torch.exp(x - margin) / (b + torch.exp(x - margin))\n",
        "        return y\n",
        "\n",
        "    def _forward_impl(self, x, age, pro, intra, inter):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # propotype update\n",
        "        z = x.cpu().clone().detach().numpy()\n",
        "        age = age.cpu().clone().detach().numpy()\n",
        "        pro_t = pro[0].copy()\n",
        "        intra_t = intra.copy()\n",
        "        inter_t = inter.copy()\n",
        "        for i in range(z.shape[0]):\n",
        "            temp = pro[0][age[i], :].copy()  # shallow copy\n",
        "            pro[0][age[i]] = pro[0][age[i], :] + (z[i] - pro[0][age[i], :]) / (pro[1][age[i]] + 1)  # update Prototype\n",
        "            pro[1][age[i]] += 1  # update instance number\n",
        "            # cosine_distances 0~2 Divisor 0 is set to 1 for unknown relationship\n",
        "            intra[age[i]] = intra[age[i]] + cosine_distance(z[i], temp) * cosine_distance(z[i], pro[0][age[i]])\n",
        "        # Calculate distance between two matrices and multi-row vectors\n",
        "        inter = cosine_distance(pro[0], pro[0])\n",
        "        delta_pro = np.concatenate((pro[0]-pro_t, intra-intra_t, inter-inter_t), axis=1)[np.newaxis, :]\n",
        "        pro_input = np.concatenate((pro[0], intra), axis=1)[np.newaxis, :]\n",
        "        m_l = self.margin_long_tail(torch.from_numpy(delta_pro).cuda())\n",
        "        m_p_miu = self.margin_miu(torch.from_numpy(pro_input).cuda())\n",
        "        m_p_sigma = self.margin_sigma(torch.from_numpy(pro_input).cuda())\n",
        "        m_p = self.gaussian(z, age, m_p_miu, m_p_sigma)\n",
        "        margin = m_p + 0.1*m_l\n",
        "        # The margin is normalized to 0 as the mean and 1 as the variance\n",
        "        margin = (margin-torch.mean(margin, dim=1).expand([101, -1]).permute(1, 0))/torch.std(margin, dim=1).expand([101, -1]).permute(1, 0)\n",
        "        margin = margin*0.01\n",
        "        if not False: #cfg.model.margin: эта штука False у них стоит\n",
        "            margin = margin*0\n",
        "        x = self.fc(x)\n",
        "        if margin.requires_grad:\n",
        "            x = F.softmax(x-margin, dim=1)  # make a baseline\n",
        "            # x = F.softmax(x-margin, dim=1)\n",
        "        else:\n",
        "            x =F.softmax(x, dim=1)\n",
        "        # L1 normalize\n",
        "        # x = F.normalize(x-margin, p=1, dim=1)  # negative logarithm possible\n",
        "        return x, pro, intra, inter\n",
        "\n",
        "    def forward(self, x, age, proc, intra, inter):\n",
        "        return self._forward_impl(x, age, proc, intra, inter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l0uHoa2V31I"
      },
      "outputs": [],
      "source": [
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        # partial load pretrained model\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHBFt0ofWd-f"
      },
      "outputs": [],
      "source": [
        "def resnet34(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6sIMFoZIeeV"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  img = Image.open(img).convert('RGB')\n",
        "  imgs = [img, img.transpose(Image.FLIP_LEFT_RIGHT)]\n",
        "  transform_list = [\n",
        "      transforms.Resize((224, 224), interpolation=3),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ]\n",
        "  transform = transforms.Compose(transform_list)\n",
        "  imgs = [transform(i) for i in imgs]\n",
        "  imgs = [torch.unsqueeze(i, dim=0) for i in imgs]\n",
        "\n",
        "  return imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX5wvA3TMQjz"
      },
      "outputs": [],
      "source": [
        "model = resnet34(pretrained=True, progress=True)\n",
        "fc_in_features = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(fc_in_features, 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NfyXGtf-1in"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "mtcnn = MTCNN(post_process=False, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfnSKziLYCYj",
        "outputId": "b826a6d1-ac43-422a-b547-74fc925b0e01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeKhLRBJROPN"
      },
      "outputs": [],
      "source": [
        "state = torch.load('/content/best.pth')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm5LVSeRMSz-"
      },
      "outputs": [],
      "source": [
        "# state = torch.load('/content/best.pth')\n",
        "model.load_state_dict(state)\n",
        "# model = model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrsOyGli-SIZ"
      },
      "outputs": [],
      "source": [
        "def alignment_procedure(img, left_eye, right_eye):\n",
        "    #this function aligns given face in img based on left and right eye coordinates\n",
        "    \n",
        "    left_eye_x, left_eye_y = left_eye\n",
        "    right_eye_x, right_eye_y = right_eye\n",
        "    \n",
        "    #-----------------------\n",
        "    #find rotation direction\n",
        "    \n",
        "    if left_eye_y > right_eye_y:\n",
        "        point_3rd = (right_eye_x, left_eye_y)\n",
        "        direction = -1 #rotate same direction to clock\n",
        "    else:\n",
        "        point_3rd = (left_eye_x, right_eye_y)\n",
        "        direction = 1 #rotate inverse direction of clock\n",
        "    \n",
        "    #-----------------------\n",
        "    #find length of triangle edges\n",
        "    \n",
        "    a = euclidean(left_eye, point_3rd)\n",
        "    b = euclidean(right_eye, point_3rd)\n",
        "    c = euclidean(right_eye, left_eye)\n",
        "    \n",
        "    #-----------------------\n",
        "    \n",
        "    #apply cosine rule\n",
        "    \n",
        "    if b != 0 and c != 0: #this multiplication causes division by zero in cos_a calculation\n",
        "    \n",
        "        cos_a = (b*b + c*c - a*a)/(2*b*c)\n",
        "        angle = np.arccos(cos_a) #angle in radian\n",
        "        angle = (angle * 180) / math.pi #radian to degree\n",
        "    \n",
        "        #-----------------------\n",
        "        #rotate base image\n",
        "    \n",
        "        if direction == -1:\n",
        "            angle = 90 - angle\n",
        "    \n",
        "        img = Image.fromarray(img)\n",
        "        img = np.array(img.rotate(direction * angle))\n",
        "    \n",
        "    #-----------------------\n",
        "    \n",
        "    return img #return img anyway"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg4FQWuj_Ee6"
      },
      "outputs": [],
      "source": [
        "def detect_face(input_path):\n",
        "    img = cv2.imread(input_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    bbox, _, landmarks = mtcnn.detect(img, landmarks=True)\n",
        "\n",
        "    if bbox is None:\n",
        "        # self.non_detect.append(self.path + img_path)\n",
        "        return \"can't detect\"\n",
        "    if landmarks is None:\n",
        "        # self.non_align.append(self.path + img_path)\n",
        "        return \"can't detect\"\n",
        "\n",
        "\n",
        "    bbox = list(map(int, bbox[0]))\n",
        "    bbox = [max(0, int(x)) for x in bbox]\n",
        "    img = img[bbox[1]: bbox[3], bbox[0]: bbox[2], :]\n",
        "    align = alignment_procedure(img, (int(landmarks[0][0][0]),\n",
        "                    int(landmarks[0][0][1])),\n",
        "                    (int(landmarks[0][1][0]), \n",
        "                    int(landmarks[0][1][1])))\n",
        "    \n",
        "    return align, img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5pfOdexLkyA"
      },
      "outputs": [],
      "source": [
        "def inference(img_path, uid):\n",
        "    \n",
        "    rank = torch.Tensor([i for i in range(101)]).cuda()\n",
        "\n",
        "    age = 20\n",
        "    age = torch.IntTensor([int(age)])\n",
        "    age = age.to(device)\n",
        "\n",
        "    p = detect_face(img_path)\n",
        "\n",
        "    if type(p) == str:\n",
        "        return \"MTCNN can't detect face\"\n",
        "    else:\n",
        "        align, not_align = p\n",
        "        align = cv2.cvtColor(align, cv2.COLOR_BGR2RGB)\n",
        "        not_align = cv2.cvtColor(not_align, cv2.COLOR_BGR2RGB)\n",
        "        cv2.imwrite(str(uid) + 'align.jpg', align) \n",
        "        cv2.imwrite(str(uid) + 'not_align.jpg', not_align)\n",
        "        imgs = preprocess(str(uid) + 'align.jpg')\n",
        "        imgs2 = preprocess(str(uid) + 'not_align.jpg')\n",
        "        predict_age_align = 0\n",
        "        predict_age_not_align = 0\n",
        "        prototype = np.zeros([101, 512], dtype=np.float32)\n",
        "        instance_num = np.zeros([101, 1], dtype=np.float32)\n",
        "        intra = np.zeros([101, 1], dtype=np.float32)\n",
        "        inter = np.zeros([101, 101], dtype=np.float32)\n",
        "        pro = [prototype, instance_num]\n",
        "\n",
        "        for img in imgs:\n",
        "            img = img.to(device)\n",
        "            output, pro, intra, inter = model(img, age, pro, intra, inter)\n",
        "            predict_age_align += torch.sum(output * rank, dim=1).item() / 2\n",
        "\n",
        "        for img in imgs2:\n",
        "            img = img.to(device)\n",
        "            output, pro, intra, inter = model(img, age, pro, intra, inter)\n",
        "            predict_age_not_align += torch.sum(output * rank, dim=1).item() / 2\n",
        "\n",
        "    # print(predict_age_align)\n",
        "    # print(predict_age_not_align)\n",
        "\n",
        "    return predict_age_align, predict_age_not_align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtuBaQyPEU9V"
      },
      "outputs": [],
      "source": [
        "def preprocess_photo(photo, uid, postfix):\n",
        "    fileID = photo.photo[-1].file_id\n",
        "\n",
        "    file_info = bot.get_file(fileID)\n",
        "\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "    path = '../' + str(uid) + postfix + \".jpg\"\n",
        "    with open(path, 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "    return path#open(str(uid) + postfix + \".jpg\", 'rb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSO8F0lOJpXE"
      },
      "outputs": [],
      "source": [
        "# os.mkdir('/content/AgeEstimationLogs/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma6G6Wf_IupL",
        "outputId": "1796d631-b789-4b32-f010-229f576c799c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d = {}\n",
        "\n",
        "for e in os.listdir('/content/AgeEstimationLogs/'):\n",
        "    if e == '.ipynb_checkpoints':\n",
        "      break\n",
        "    d[int(e)] = len(list(os.listdir('/content/AgeEstimationLogs/' + e)))\n",
        "\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jGl1X8TEgHN"
      },
      "outputs": [],
      "source": [
        "bot = telebot.TeleBot('...') # insert ur token here\n",
        "\n",
        "users = dict()\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "    user_id = message.from_user.id\n",
        "    bot.send_message(message.chat.id, 'Привет! Тут можно оценить свой возраст, лол\\nНапиши /help, если ты не знаешь как со мной работать.')\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['help'])\n",
        "def start_message(message):\n",
        "    user_id = message.from_user.id\n",
        "    bot.send_message(message.chat.id, 'Отправь мне фотографию, я оценю твой возраст! :)')\n",
        "\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['photo'])\n",
        "def send_photo(photo):\n",
        "    user_id = photo.from_user.id\n",
        "\n",
        "    if user_id not in d.keys():\n",
        "        d[user_id] = 0\n",
        "        os.mkdir('/content/AgeEstimationLogs/' + str(user_id))\n",
        "\n",
        "    img_path = preprocess_photo(photo, user_id, 'age')\n",
        "\n",
        "    p = inference(img_path, user_id)\n",
        "    if type(p[0]) == str:\n",
        "        message = p\n",
        "    else:\n",
        "        p1, p2 = p\n",
        "        message = f'alignment face prediction: {p1}\\nnot alignment face prediction: {p2}'\n",
        "    \n",
        "    d[user_id] += 1\n",
        "    if type(p[0]) != str:\n",
        "      shutil.copyfile(img_path, '/content/AgeEstimationLogs/' + str(user_id) + '/' + str(d[user_id]) + '_' + str(p[0]) + '_' + str(p[1]) + '.jpg')\n",
        "    else:\n",
        "      shutil.copyfile(img_path, '/content/AgeEstimationLogs/' + str(user_id) + '/' + str(d[user_id]) + '.jpg')\n",
        "\n",
        "    # save correctly using uid, d[uid]\n",
        "\n",
        "    bot.send_message(photo.chat.id, message)\n",
        "\n",
        "\n",
        "\n",
        "bot.polling()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW399u9uGDJA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}